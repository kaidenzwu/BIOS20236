{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e19e39b-82ed-4f00-b7ab-75914e6aa75a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HW 5: Choose your own adventure.\n",
    "The goal of this last homework is to capitalize on the skills you have developed to perform a more open ended analysis of a dataset. To complete this HW you only need to CHOOSE ONE of the three prompts below and make an attempt.  Do your best, justify you answer to the question posed in each case using what we have learned during the quarter. Some problems are more open ended then others as noted in the prompts.  Choose your problem according to your skills and motivations.  30 pts total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84efbc-bc3e-471a-8cde-373899bcdf18",
   "metadata": {},
   "source": [
    "### Option 1: predicting phenotype with random forest regression.\n",
    "Paper: Zeqian Li, Ahmed Selim, Seppe Kuehn. PLoS Comp Biol. 2023. https://doi.org/10.1371/journal.pcbi.1011705\n",
    "\n",
    "**I expect this to be straightforward. The main challenge will be getting familiar with setting up and running random forest regression. The data is already in a form that should be easy to work with.**\n",
    "\n",
    "In this paper we took ~100 different bacterial isolates and for each one we measured whether or not it could grow using 10 different carbon sources.  The experiment was to put them in media conditions with each carbon source in isolation, wait a couple of days, and measure if any growth had occurred.  Then we wanted to see if we could predict this binary (growth/no-growth) phenotype from the genes (presence/absence) that each strain possessed. We ended up doing this regression using random forests. I want you to try and recapitulate a random forest regression using these data.\n",
    "\n",
    "The growth measurements are in the zeqian_growth_data_final.csv (call this matrix P)\n",
    "* rows are strains\n",
    "* columns are carbon sources\n",
    "\n",
    "The gene presence/absence matrix is in zeqian_ko_data_final.csv  (call this matrix G)\n",
    "* rows are strains\n",
    "* columns are genes designated by KEGG Orthology groups (https://www.genome.jp/kegg/)\n",
    "\n",
    "**First** What I want you to do is pick a column of P (any one) and regress it on ALL columns of G using a random forest regression.  So use the presence and absence of all the genes when trying to predict P. Note, use the built in Python regression package sklearn.ensemble.RandomForestRegressor.\n",
    "\n",
    "**Second** I want you to assess the out of sample predictive power of the model using cross validation.  Does it work?\n",
    "\n",
    "**Third** Now go look carefully at the paper.  When you chose your test set for CV how did you select the strains (rows) to hold out?  Why do you think the regression is working?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df5e49c2-9ee9-4682-9b36-048ce6a6e98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>Arabinose</th>\n",
       "      <th>Butyrate</th>\n",
       "      <th>Deoxyribose</th>\n",
       "      <th>Glucuronic acid</th>\n",
       "      <th>Glycerol</th>\n",
       "      <th>Mannitol</th>\n",
       "      <th>Mannose</th>\n",
       "      <th>Melibiose</th>\n",
       "      <th>Propionate</th>\n",
       "      <th>Raffinose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HMWF001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HMWF003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HMWF005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HMWF006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HMWF008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sif2233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>sif2332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>sif2416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>sif2431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>sif2433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     strain  Arabinose  Butyrate  Deoxyribose  Glucuronic acid  Glycerol  \\\n",
       "0   HMWF001        0.0       0.0          0.0              0.0       0.0   \n",
       "1   HMWF003        0.0       0.0          0.0              0.0       0.0   \n",
       "2   HMWF005        1.0       NaN          0.0              0.0       1.0   \n",
       "3   HMWF006        1.0       NaN          0.0              0.0       1.0   \n",
       "4   HMWF008        0.0       0.0          0.0              0.0       0.0   \n",
       "..      ...        ...       ...          ...              ...       ...   \n",
       "91  sif2233        1.0       NaN          0.0              NaN       1.0   \n",
       "92  sif2332        0.0       1.0          0.0              0.0       0.0   \n",
       "93  sif2416        1.0       0.0          0.0              0.0       1.0   \n",
       "94  sif2431        0.0       1.0          0.0              0.0       1.0   \n",
       "95  sif2433        1.0       0.0          0.0              0.0       1.0   \n",
       "\n",
       "    Mannitol  Mannose  Melibiose  Propionate  Raffinose  \n",
       "0        0.0      0.0        0.0         0.0        0.0  \n",
       "1        0.0      0.0        0.0         0.0        0.0  \n",
       "2        1.0      1.0        0.0         1.0        0.0  \n",
       "3        1.0      1.0        0.0         1.0        0.0  \n",
       "4        0.0      0.0        0.0         0.0        0.0  \n",
       "..       ...      ...        ...         ...        ...  \n",
       "91       1.0      1.0        0.0         NaN        0.0  \n",
       "92       0.0      0.0        0.0         1.0        0.0  \n",
       "93       1.0      1.0        0.0         0.0        0.0  \n",
       "94       0.0      0.0        0.0         1.0        0.0  \n",
       "95       1.0      1.0        0.0         0.0        0.0  \n",
       "\n",
       "[96 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "matrix_p = pd.read_csv('zeqian_growth_data_final.csv')\n",
    "matrix_g = pd.read_csv('zeqian_ko_data_final.csv')\n",
    "\n",
    "matrix_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331e6fa-edb9-4a46-991f-a1aa56dbd1c0",
   "metadata": {},
   "source": [
    "### Option 2: See if you can improve on a linear regression using a neural network.\n",
    "\n",
    "**This will be more challenging since we did not actively work with neural networks. I cannot independently confirm whether nor not an NN will outperform our linear regression or not. However, the data wrangling aspects of this option were already done in project 1.  So that part is easy.**\n",
    "\n",
    "For the regressions we performed in project 1 using gene presence/absence to predict phenotypes using linear regression.  Can you improve the **out of sample** predictions using a neural network?\n",
    "\n",
    "What I want to you to do is take the regression for $r_A$ based on gene presence/absence ($x_{i,j}$) and see if you can improve.  Recall that last time we fit a model of the form:\n",
    "\n",
    "$$ r_A^i = \\beta_0 + \\sum_j \\beta_j x_{i,j}$$\n",
    "\n",
    "Instead, I want you to use a neural network to predict $$r_A^i = f(x_{i,j})$$ where the function $f$ is a neural network.  I would recommend using a multilayer perceptron feedforward neural network.  You will need to use regularization to avoid overfitting either via what is called 'dropout', early stopping during training, or (easiest) just regularization on the weights in the network. This works in the same way that the L1 penalty works for LASSO, but is applied to network weights. The one other key tweak is to make the final node of the network have a linear activation function rather than RelU. Note the number of input nodes should be the number of independent variables.  To do this I recommend using TensorFlow and Keras which are the standard machine learning NN platforms for python.  Keras is a high level package that sits on top of TensorFlow and uses it to setup NN models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999fef35-3b88-4170-9a9e-eb230b3b3795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Excel file into a pandas DataFrame\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "file_path = 'DataMatrix_Project1.xlsx'\n",
    "dataframe = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "# Filter the rows where the second column ('phenotype') includes \"NAR\"\n",
    "nar_rows = dataframe[dataframe['phenotype'].str.contains(\"NAR\")]\n",
    "\n",
    "# Correctly select the columns 2 to 19 (which are indices 1 through 18 in zero-based Python indexing)\n",
    "XA = nar_rows.iloc[:, 2:19].to_numpy()\n",
    "YRA = nar_rows['YRA'].to_numpy()\n",
    "YGA = nar_rows['YGA'].to_numpy()\n",
    "\n",
    "nir_rows = dataframe[dataframe['phenotype'].str.contains(\"NIR\")]\n",
    "XI = nir_rows.iloc[:,2:19].to_numpy()\n",
    "YRI = nir_rows['YRI'].to_numpy()\n",
    "YGI = nir_rows['YGI'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acd5dd-6528-48e8-8fbf-99da7ad1b309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57a72d99-cfa1-47cb-85e0-62e4b46d7a37",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Option 3: Dimension reduction on the global ocean microbiome.\n",
    "\n",
    "**This option is technically easier than option 2, but harder than option 1. In particular, it requires some relatively messy data wrangling followed by some relatively simple data analysis.**\n",
    "\n",
    "The question is based on this 2015 paper on the global ocean microbiome.https://www.science.org/doi/epdf/10.1126/science.1261359\n",
    "\n",
    "The dataset constructed here are measurements of taxonomic diversity for >100 samples from the ocean microbiome at various depths. For each sample they perform sequencing measurements and they also perform environmental measurements (temperature, nutrient levels, etc).  The goal here is to perform PCA on the taxonomic data and asnwer the following questions:\n",
    "\n",
    "1. Is there any low dimensional structure in a matrix that has samples as rows and abundances of taxa as columns?  That is, how much variance in the data is explained by the first couple PCs?\n",
    "2. What environmental variable, if any, is most strongly correlated with the varaition in abundances you characterized in question 1?  That is, what environmental parameter correlates most strongly with sample projections on the first PC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62eba0-2bf2-4974-9fc3-692f1c4c5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load the taxonomic data! \n",
    "D = pd.read_csv('miTAG.taxonomic.profiles.release.tsv', sep='\\t')\n",
    "D.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5cccd-5bb9-4451-9f2f-c59ed0d6a695",
   "metadata": {},
   "source": [
    "The columns of D are samples, the rows are taxa.  Note that some columns contain the string '0.22_1.6' -- and others contain '0.22_3' these refer to size fractions.  For the former, only particles in the size range of 0.22um to 1.6um were sequenced, in the latter, 0.22um to 3um.  **Restrict your analysis to the larger size fraction -- 0.22um to 3um**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be825ea-c179-415d-b4bb-d8701e3f5397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is code to load the environmental data and associated sample IDs\n",
    "EnvData = pd.read_excel('OM.CompanionTables.xlsx',sheet_name = 'Table W8')\n",
    "SampleIDs = pd.read_excel('OM.CompanionTables.xlsx',sheet_name = 'Table W1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee5c4a-904d-4560-adce-353b264cf6d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here is the data wrangling problem. \n",
    "\n",
    "EnvData has the samples as rows and the environmental parameters as columsn. The first column of EnvData contains a \"Pangaea Sample ID\" which is NOT the same as the sample names (columns) in the dataframe (D) loaded above that contains the taxonomic information. The second dataframe loaded above (SampleIDs) contains a column called \"Sample label\" that DOES match the column names in D above. It also contains a column labeled \"PANGAEA sample identifier\".  Therefore, using the SampleIDs dataframe you can match a Sample ID (column names of D) to a Pangaea label. From this matching you can then associate a row of EnvData with each samples taxonomic data.  Do this carefully and make sure you manually check a few to make sure.  You will need to do this to answer question 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83233de-9072-40e8-99c6-bb3943e3f23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
